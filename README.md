# Deep Learning Practice

The purpose of this repository is to allow me to review and practice basic deep learning principles. In it, I implement a neural network from scratch in python (MNIST_Vanilla notebook). The initial implementation simply uses a sigmoid activation function and Mean Squared Error cost function. In the MNIST_Enhancements notebook, I use the more reasonable Cross Entropy cost function, ReLU activation function, and toy around with regularization techniques. Finally, I begin practicing with TensorFlow properly in MNIST_Tensorflow.

